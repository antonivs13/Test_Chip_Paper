#! /usr/bin/python
"""Hashing all files under a directory and categorize them based on matching instances"""

import os, os.path
import sys
import hashlib, tarfile
from optparse import OptionParser
from optparse import Option

# define an extension to the OptParser class to allow multiple inputs under one option flag
# class MultipleOption(Option):
#	ACTIONS = Option.ACTIONS + ("extend",)
#		STORE_ACTIONS = Option.STORE_ACTIONS + ("extend",)
#	TYPED_ACTIONS = Option.TYPED_ACTIONS + ("extend",)
#	ALWAYS_TYPED_ACTIONS = Option.ALWAYS_TYPED_ACTIONS + ("extend",)

#	def take_action(self, action, dest, opt, value, values, parser):
#		if action == "extend":
#			values.ensure_value(dest, []).append(value)
#		else:
#			Option.take_action(self, action, dest, opt, value, values, parser)



def main():

	usage = "usage: %prog [option]."
	version = "%prog 2.0"
	parser = OptionParser(usage=usage, version=version)
	# TODO: extend the --directory option to allow multiple arguments under this option (representing failogs of different fault				 models but for the same design) and output tuples that can be easily processed to represent stacked bars by signature2csv.p			y
	parser.add_option("-d", "--directory", dest="directory",
			help="specify directory containing the tar files to be hashed", metavar="DIR")
	parser.add_option("-f", "--faults", action="append", default = [], dest="faults",
			help="[Multiple arguments] specify the fault models corresponding to the tar files under the hashing directory", metavar="STRING")
	parser.add_option("-o", "--outfile", dest="outfile",
			help="specify output file to store the signature", metavar="FILE")
	parser.add_option("--et", "--ETfault", dest="ETfault",
			help="[optional] specify ETfault file generated by Encounter test to map the hashed fault signature to the actual faults.",
			metavar= "FILE")
	parser.add_option("-c", "--cvs", action="store_true", dest="csv", default=True,
			help="[optional] generate a .csv file for the fault signatures.", metavar="FILE")
	parser.add_option("-m", "--map", dest="map",
			help="[optional] use with the --et option to specify output file to store the mapped faults.")

	(options, args) = parser.parse_args()

	if options.directory is None:
		parser.error("Please specify input directory!")
	if options.outfile is None:
		parser.error("Please specify output file!")
	if options.ETfault is not None and options.map is None:
		parser.error("Please specify output map file!")
	if options.map is not None and options.ETfault is None:
		parser.error("Please specify ETfault file!")
		
	all_models = [i.split('.', 1)[0] for i in os.listdir(options.directory)]
	my_models = options.faults
	for model in my_models:
		if model not in all_models:
			parser.error("The fault model \"%s\" you specified is not found under the hashing directory!"%(model))
	
		
	#if len(options.directory) != len(options.faults):
		#parser.error("Please make sure that you specify the correct number of fualt models and fail log directories!")
	
	# print options
	# print args

	hash_dictionary = []
	# build two dimensional array to store equivalent faults
	equivalence_array = []
	fault_count = 0
	
	#os.chdir(options.directory)
	for model in my_models:
		tar = tarfile.open(options.directory+model+".tar.gz")
		for member in tar.getnames():
			if member.endswith('.fail'):
				file = tar.extractfile(member)
				content = file.read()
				# use the sha algorithm instead of MD5 due to considerations of collision
				myHash = hashlib.sha256(content).digest()
				if myHash not in hash_dictionary:
					hash_dictionary.append(myHash)
					# add another row to equivalence array
					equivalence_array.append([])
				# append fault to equivalence array
				index = hash_dictionary.index(myHash)
				equivalence_array[index].append(str(member.split('/')[-1])[0:-5]+"_"+model)
				fault_count = fault_count + 1

	# for i in range(len(options.directory)):
		# for root, dirnames, files in os.walk(options.directory[i]):
			# for file in files:
				# if str(file)[-5:] == ".fail":
					# # assign hash to each file
					# with open(options.directory[i]+file) as myFile:
						# content = myFile.read()
						# #print(content)
						# # use the sha algorithm instead of MD5 due to considerations of collision
						# myHash = hashlib.sha256(content).digest()
						# if myHash not in hash_dictionary:
							# hash_dictionary.append(myHash)
							# # add another row to equivalence array
							# equivalence_array.append([])
						# # append fault to equivalence array
						# index = hash_dictionary.index(myHash)
						# equivalence_array[index].append(str(file)[0:-5]+"_"+str(options.faults[i]))
						# fault_count = fault_count + 1
				
	# write equivalence array to output file
	with open(options.outfile+'.sig', 'w') as outfile:
		for i in range(len(equivalence_array)):
			outfile.write('{ ')
			for j in range(len(equivalence_array[i])):
				outfile.write(equivalence_array[i][j])
				outfile.write(' ')
			outfile.write('}\n')
	outfile.close()

	# generate map file if specified
	if options.ETfault is not None and options.map is not None:
			signature_mapping(equivalence_array, options.ETfault, options.map, equivalence_array)	
			
	# write csv file
	if options.csv:
		sig2csv(my_models, options.outfile)

	equivalent_faults = len(equivalence_array)
	# print(equivalence_array)
	# report detected fault response to catch undeteced faults	
	print("There were " + str(fault_count) + " fail logs and " + str(equivalent_faults) + " unique fault signatures.")
	


def signature_mapping(signature, fault, outfile, fault_equivalence):
	fault_array = []
	with open(fault, 'r') as infile:
		for line in infile:
			if len(line.split()) > 3 and line.split()[1] == "u":
				fault_index = int(line.split()[0])
				pin = line.split()[-1]
				fault = line.split()[2]
				# append new row to fault array
				fault_array.append([])
				fault_array[-1].append(pin)
				fault_array[-1].append(fault)
	infile.close()

	# map fault signature to actual fault and write out the result
	with open(outfile, 'w') as outfile:
		for i in range(len(fault_equivalence)):
			outfile.write('{')
			for j in range(len(fault_equivalence[i])):
				index = int(fault_equivalence[i][j]) - 1
				outfile.write(' [' + str(fault_array[index][0]) + ' ' + str(fault_array[index][1] + '] '))
			outfile.write('}\n')






	outfile.close()


	
def sig2csv(models, filename):
	# read each line in the signature file and count number of faults in each equivalent fault class
	model_size = len(models)
	fault_count = [0] * model_size
	x_axis = []
	sig_size_array = []
	output_array = []
	outlier_array = []
	unique_sig_count = 0
	with open(filename+'.sig', 'r') as infile:
		for line in infile:
			# split the line and ignore the curly brackets
			myFaults = line.split()[1:-1]
			# the last entry of fault_array is the sum of fail log counts across all fault models for the current fault signature
			fault_array = [0] * (model_size+1)
			# print(myFaults)

			# count how many fail logs have the current fault signature and store them based on their fault models
			for n in range(model_size):
				for i in myFaults:
					if models[n] in i:
						fault_count[n] = fault_count[n] + 1
						fault_array[n] = fault_array[n] + 1
			fault_array[-1] = sum(fault_array[:-1])
			x_axis.append(fault_array[-1])
			# print(fault_array)
			# append fault array to sig_size_array
			#sig_size_array.append([])
			sig_size_array.append(fault_array)
			# if options.outlier:
			#	if class_size > int(options.threshold):
			#		outlier_array.append(line)
			unique_sig_count = unique_sig_count + 1
	infile.close()

	# sort sig_size_array according to the last column
	sig_size_array = sorted(sig_size_array, key=lambda l:l[-1])

	# collapse class size array into simplified 2D list: [[signature_group_size_1, count_from_fault_model_1, count_from_fault_model_2, ..., mixed(fail logs from different fault models share the same fault signature)], [signature_group_size_2, count_from_fault_model_1, count_from_fault_model_2, ..., mixed], ...]
	x_axis = list(set(x_axis))

	for i in x_axis:
		output_array.append([])
		output_array[-1] = [0] * (model_size + 2)
		output_array[-1][0] = i
		for j in range(len(sig_size_array)):
			if sig_size_array[j][-1] == i:
				# if only one fault model contributes to this fault signature
				if sig_size_array[j].count(0) == model_size - 1:
					# print(sig_size_array[j])
					# print(sig_size_array[j].index(i))
					output_array[-1][sig_size_array[j].index(i)+1] = output_array[-1][sig_size_array[j].index(i)+1] + 1
				else:
					output_array[-1][-1] = output_array[-1][-1] + 1

	# write fault array to output file in csv format
	with open(filename+'.csv', 'w') as outfile:
		for i in range(len(output_array)):
			for j in range(len(output_array[0])):
				outfile.write(str(output_array[i][j]) + ",")
			# sum of faults
			outfile.write(str(output_array[i][0] * sum(output_array[i][1:])) + '\n')
	outfile.close()



if __name__ == '__main__':
	main()
